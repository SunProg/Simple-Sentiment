{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import random\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fold_10(set_of_documents):\n",
    "    \"\"\"\n",
    "    Simple 10 folds CV\n",
    "    \"\"\"\n",
    "    size = len(set_of_documents)\n",
    "    index_interval = int(size / 10)\n",
    "    \n",
    "    ten_folds = []\n",
    "    for i in range(10):\n",
    "        start_index = int(i * index_interval)\n",
    "        if i == 9:\n",
    "            ten_folds.append(set_of_documents[start_index:])\n",
    "        else:\n",
    "            ten_folds.append(set_of_documents[start_index:start_index + index_interval])\n",
    "    \n",
    "    res = []\n",
    "    for i in range(10):\n",
    "        _test_set = ten_folds[i]\n",
    "        _training_set = []\n",
    "        for j in range(10):\n",
    "            if j == i:\n",
    "                continue\n",
    "            for elem in ten_folds[j]:\n",
    "                _training_set.append(elem)\n",
    "        ith_fold = [_training_set, _test_set]\n",
    "        res.append(ith_fold)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.word_probs = []\n",
    "        self.log_prior = {}\n",
    "        self.pos_words = {}\n",
    "        self.neg_words = {}\n",
    "        self.log_likelihood_pos = {}\n",
    "        self.log_likelihood_neg = {}\n",
    "        \n",
    "    def calculate_frequency(self, training_data):\n",
    "        # 각 Class 빈도 계산\n",
    "        num_pos = 0\n",
    "        num_neg = 0\n",
    "        exceptions = [',', '.', 't']        \n",
    "        for docu in training_data:\n",
    "            if docu[1] == 'pos':\n",
    "                num_pos += 1\n",
    "                for word in docu[0]:\n",
    "#                     if len(word) == 1 and word not in exceptions:\n",
    "#                         continue\n",
    "                    if word in self.pos_words:\n",
    "                        self.pos_words[word] += 1\n",
    "                    else:\n",
    "                        self.pos_words[word] = 1\n",
    "            else:\n",
    "                num_neg += 1\n",
    "                for word in docu[0]:\n",
    "                    if word in self.neg_words:\n",
    "                        self.neg_words[word] += 1\n",
    "                    else:\n",
    "                        self.neg_words[word] = 1\n",
    "        \n",
    "        return (num_pos, num_neg)\n",
    "                    \n",
    "    def log_likelihood(self):\n",
    "        count_all_pos = 0\n",
    "        count_all_neg = 0\n",
    "        for word in self.pos_words:\n",
    "            count_all_pos = count_all_pos + self.pos_words[word] + 1\n",
    "        \n",
    "        for word in self.neg_words:\n",
    "            count_all_neg = count_all_neg + self.neg_words[word] + 1\n",
    "            \n",
    "        for word in self.pos_words:\n",
    "            self.log_likelihood_pos[word] = math.log2((self.pos_words[word] + 1)  \n",
    "                                                / count_all_pos)\n",
    "        \n",
    "        for word in self.neg_words:\n",
    "            self.log_likelihood_neg[word] = math.log2((self.neg_words[word] + 1) \n",
    "                                                / count_all_neg)\n",
    "        self.smoothing_pos = math.log2(1 / count_all_pos)\n",
    "        self.smoothing_neg = math.log2(1 / count_all_neg)\n",
    "        \n",
    "        \n",
    "    def train(self, training_data):\n",
    "        num_doc = len(training_data)\n",
    "        print('num doc : %d' %(num_doc))\n",
    "        num_pos, num_neg = self.calculate_frequency(training_data)\n",
    "        \n",
    "        self.log_prior['pos'] = math.log2(num_pos / num_doc)\n",
    "        self.log_prior['neg'] = math.log2(num_neg / num_doc)\n",
    "        \n",
    "        self.log_likelihood()\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        sum_pos = self.log_prior['pos']\n",
    "        sum_neg = self.log_prior['neg']\n",
    "        word_in_docu_pos = {}\n",
    "        word_in_docu_neg = {}\n",
    "        \n",
    "        for word in test_data[0]:\n",
    "            if word in self.log_likelihood_pos:\n",
    "                if word in word_in_docu_pos:\n",
    "                    continue\n",
    "                else:\n",
    "                    sum_pos += self.log_likelihood_pos[word]\n",
    "                    word_in_docu_pos[word] = 1\n",
    "            else:\n",
    "                if not word in word_in_docu_pos:\n",
    "                    sum_pos += self.smoothing_pos\n",
    "                    word_in_docu_pos[word] = 1\n",
    "            if word in self.log_likelihood_neg:\n",
    "                if word in word_in_docu_neg:\n",
    "                    continue\n",
    "                else:\n",
    "                    sum_neg += self.log_likelihood_neg[word]\n",
    "                    word_in_docu_neg[word] = 1\n",
    "            else:\n",
    "                if not word in word_in_docu_neg:\n",
    "                    sum_neg += self.smoothing_neg\n",
    "                    word_in_docu_neg[word] = 1\n",
    "\n",
    "        if sum_pos > sum_neg:\n",
    "            return 'pos'\n",
    "        else:\n",
    "            return 'neg'\n",
    "    \n",
    "    def accuracy(self, test_data):\n",
    "        data_size = len(test_data)\n",
    "        correct_num = 0\n",
    "        for docu in test_data:\n",
    "            if self.predict(docu) == docu[1]:\n",
    "                correct_num += 1\n",
    "                \n",
    "        return float(correct_num / data_size)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifierBinary:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.log_prior = {}\n",
    "        self.pos_words = {}\n",
    "        self.neg_words = {}\n",
    "        self.log_likelihood_pos = {}\n",
    "        self.log_likelihood_neg = {}\n",
    "\n",
    "        \n",
    "\n",
    "    def calculate_frequency(self, training_data):\n",
    "        # 각 Class 빈도 계산\n",
    "        num_pos = 0\n",
    "        num_neg = 0\n",
    "        exceptions = [',', '.', 't']\n",
    "        for docu in training_data:\n",
    "            docu_word_pos = {}\n",
    "            docu_word_neg = {}\n",
    "            if docu[1] == 'pos':\n",
    "                num_pos += 1\n",
    "                for word in docu[0]:\n",
    "#                     if len(word) == 1 and word not in exceptions:\n",
    "#                         continue\n",
    "                    if word in self.pos_words:\n",
    "                        if word not in docu_word_pos:\n",
    "                            self.pos_words[word] += 1\n",
    "                            docu_word_pos[word] = 1\n",
    "                    else:\n",
    "                        self.pos_words[word] = 1\n",
    "            else:\n",
    "                num_neg += 1\n",
    "                for word in docu[0]:\n",
    "                    if word in self.neg_words:\n",
    "                        if word not in docu_word_neg:\n",
    "                            self.neg_words[word] += 1\n",
    "                            docu_word_neg[word] = 1\n",
    "                    else:\n",
    "                        self.neg_words[word] = 1\n",
    "        \n",
    "        return (num_pos, num_neg)\n",
    "                    \n",
    "    def log_likelihood(self):\n",
    "        count_all_pos = 0\n",
    "        count_all_neg = 0\n",
    "        for word in self.pos_words:\n",
    "            count_all_pos = count_all_pos + 1\n",
    "        \n",
    "        for word in self.neg_words:\n",
    "            count_all_neg = count_all_neg + 1\n",
    "            \n",
    "        for word in self.pos_words:\n",
    "            self.log_likelihood_pos[word] = math.log2((self.pos_words[word])  \n",
    "                                                / count_all_pos)\n",
    "        \n",
    "        for word in self.neg_words:\n",
    "            self.log_likelihood_neg[word] = math.log2((self.neg_words[word]) \n",
    "                                                / count_all_neg)\n",
    "        \n",
    "        self.smoothing_pos = math.log2(1 / count_all_pos)\n",
    "        self.smoothing_neg = math.log2(1 / count_all_neg)\n",
    "\n",
    "        \n",
    "        \n",
    "    def train(self, training_data):\n",
    "        num_doc = len(training_data)\n",
    "        print('num doc : %d' %(num_doc))\n",
    "        num_pos, num_neg = self.calculate_frequency(training_data)\n",
    "        \n",
    "        self.log_prior['pos'] = math.log2(num_pos / num_doc)\n",
    "        self.log_prior['neg'] = math.log2(num_neg / num_doc)\n",
    "        \n",
    "        self.log_likelihood()\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        sum_pos = self.log_prior['pos']\n",
    "        sum_neg = self.log_prior['neg']\n",
    "        word_in_docu_pos = {}\n",
    "        word_in_docu_neg = {}\n",
    "\n",
    "        for word in test_data[0]:\n",
    "            if word in self.log_likelihood_pos:\n",
    "                if word in word_in_docu_pos:\n",
    "                    continue\n",
    "                else:\n",
    "                    sum_pos += self.log_likelihood_pos[word]\n",
    "                    word_in_docu_pos[word] = 1\n",
    "            else:\n",
    "                if not word in word_in_docu_pos:\n",
    "                    sum_pos += self.smoothing_pos\n",
    "                    word_in_docu_pos[word] = 1\n",
    "            if word in self.log_likelihood_neg:\n",
    "                if word in word_in_docu_neg:\n",
    "                    continue\n",
    "                else:\n",
    "                    sum_neg += self.log_likelihood_neg[word]\n",
    "                    word_in_docu_neg[word] = 1\n",
    "            else:\n",
    "                if not word in word_in_docu_neg:\n",
    "                    sum_neg += self.smoothing_neg\n",
    "                    word_in_docu_neg[word] = 1\n",
    "\n",
    "        if sum_pos > sum_neg:\n",
    "            return 'pos'\n",
    "        else:\n",
    "            return 'neg'\n",
    "\n",
    "    def accuracy(self, test_data):\n",
    "        data_size = len(test_data)\n",
    "        correct_num = 0\n",
    "        for docu in test_data:\n",
    "            if self.predict(docu) == docu[1]:\n",
    "                correct_num += 1\n",
    "                \n",
    "        return float(correct_num / data_size)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifierNegation:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.word_probs = []\n",
    "        self.log_prior = {}\n",
    "        self.pos_words = {}\n",
    "        self.neg_words = {}\n",
    "        self.log_likelihood_pos = {}\n",
    "        self.log_likelihood_neg = {}\n",
    "    \n",
    "    def word_count(self, word, pos_neg):\n",
    "        if pos_neg:\n",
    "            if word in self.pos_words:\n",
    "                self.pos_words[word] += 1\n",
    "            else:\n",
    "                self.pos_words[word] = 1\n",
    "        else:\n",
    "            if word in self.neg_words:\n",
    "                self.neg_words[word] += 1\n",
    "            else:\n",
    "                self.neg_words[word] = 1\n",
    "    \n",
    "    def calculate_frequency(self, training_data):\n",
    "        # 각 Class 빈도 계산\n",
    "        num_pos = 0\n",
    "        num_neg = 0\n",
    "        exceptions = [',', '.', 't']\n",
    "        for docu in training_data:\n",
    "            negation = False # Negation Check\n",
    "            pos_neg = (docu[1] == 'pos')\n",
    "            #positive <- True / negative <- False    \n",
    "            if docu[1] == 'pos':\n",
    "                num_pos += 1\n",
    "            else:\n",
    "                num_neg += 1\n",
    "            \n",
    "            for word in docu[0]:\n",
    "#                 if len(word) == 1 and word not in exceptions:\n",
    "#                     continue\n",
    "                \n",
    "                if word == ',' or word == '.':\n",
    "                    negation = False\n",
    "                    continue\n",
    "                if word == 'not' or word == 'no' or word == 't':\n",
    "                    negation = True\n",
    "                    continue\n",
    "                \n",
    "                if negation: # Negation 시 not_word\n",
    "                    self.word_count('not_'+word, pos_neg)                 \n",
    "                else:\n",
    "                    self.word_count(word, pos_neg)\n",
    "            \n",
    "        \n",
    "        return (num_pos, num_neg)\n",
    "                    \n",
    "    def log_likelihood(self):\n",
    "        # Log-likelihood 계산\n",
    "        count_all_pos = 0\n",
    "        count_all_neg = 0\n",
    "        for word in self.pos_words:\n",
    "            count_all_pos = count_all_pos + self.pos_words[word] + 1\n",
    "        \n",
    "        for word in self.neg_words:\n",
    "            count_all_neg = count_all_neg + self.neg_words[word] + 1\n",
    "            \n",
    "        for word in self.pos_words:\n",
    "            self.log_likelihood_pos[word] = math.log2((self.pos_words[word] + 1)  \n",
    "                                                / count_all_pos)\n",
    "        \n",
    "        for word in self.neg_words:\n",
    "            self.log_likelihood_neg[word] = math.log2((self.neg_words[word] + 1) \n",
    "                                                / count_all_neg)\n",
    "        self.smoothing_pos = math.log2(1 / count_all_pos)\n",
    "        self.smoothing_neg = math.log2(1 / count_all_neg)\n",
    "        \n",
    "        \n",
    "    def train(self, training_data):\n",
    "        # Triaing 과정\n",
    "        num_doc = len(training_data)\n",
    "        print('num doc : %d' %(num_doc))\n",
    "        # pos/neg 단어 빈도수 계산\n",
    "        num_pos, num_neg = self.calculate_frequency(training_data)\n",
    "        \n",
    "        \n",
    "        self.log_prior['pos'] = math.log2(num_pos / num_doc)\n",
    "        self.log_prior['neg'] = math.log2(num_neg / num_doc)\n",
    "        \n",
    "        self.log_likelihood()\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        sum_pos = self.log_prior['pos']\n",
    "        sum_neg = self.log_prior['neg']\n",
    "        word_in_docu_pos = {}\n",
    "        word_in_docu_neg = {}\n",
    "        negation = False\n",
    "        # Bag-of-words로 구현\n",
    "        for word in test_data[0]:\n",
    "            if word == 'not' or word == 'no' or word == 't':\n",
    "                negation = True\n",
    "                continue\n",
    "            \n",
    "            if negation:\n",
    "                word = 'not_'\n",
    "            if word in self.log_likelihood_pos:\n",
    "                if word in word_in_docu_pos:\n",
    "                    continue\n",
    "                else:\n",
    "                    sum_pos += self.log_likelihood_pos[word]\n",
    "                    word_in_docu_pos[word] = 1\n",
    "            else:\n",
    "                if not word in word_in_docu_pos:\n",
    "                    sum_pos += self.smoothing_pos\n",
    "                    word_in_docu_pos[word] = 1\n",
    "            if word in self.log_likelihood_neg:\n",
    "                if word in word_in_docu_neg:\n",
    "                    continue\n",
    "                else:\n",
    "                    sum_neg += self.log_likelihood_neg[word]\n",
    "                    word_in_docu_neg[word] = 1\n",
    "            else:\n",
    "                if not word in word_in_docu_neg:\n",
    "                    sum_neg += self.smoothing_neg\n",
    "                    word_in_docu_neg[word] = 1\n",
    "\n",
    "        if sum_pos > sum_neg:\n",
    "            return 'pos'\n",
    "        else:\n",
    "            return 'neg'\n",
    "\n",
    "        \n",
    "    \n",
    "    # Accuracy 계산\n",
    "    def accuracy(self, test_data):\n",
    "        data_size = len(test_data)\n",
    "        correct_num = 0\n",
    "        for docu in test_data:\n",
    "            if self.predict(docu) == docu[1]:\n",
    "                correct_num += 1\n",
    "                \n",
    "        return float(correct_num / data_size)\n",
    "                \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifierNegationBinary:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.word_probs = []\n",
    "        self.log_prior = {}\n",
    "        self.pos_words = {}\n",
    "        self.neg_words = {}\n",
    "        self.log_likelihood_pos = {}\n",
    "        self.log_likelihood_neg = {}\n",
    "    \n",
    "    def word_count(self, word, pos_neg):\n",
    "        if pos_neg:\n",
    "            if word in self.pos_words:\n",
    "                self.pos_words[word] += 1\n",
    "            else:\n",
    "                self.pos_words[word] = 1\n",
    "        else:\n",
    "            if word in self.neg_words:\n",
    "                self.neg_words[word] += 1\n",
    "            else:\n",
    "                self.neg_words[word] = 1\n",
    "    \n",
    "    def calculate_frequency(self, training_data):\n",
    "        # 각 Class 빈도 계산\n",
    "        num_pos = 0\n",
    "        num_neg = 0\n",
    "        \n",
    "        exceptions = [',', '.', 't']\n",
    "        for docu in training_data:\n",
    "            docu_word = [{}, {}]\n",
    "            negation = False # Negation Check\n",
    "            pos_neg = (docu[1] == 'pos')\n",
    "            #positive <- True / negative <- False    \n",
    "            if docu[1] == 'pos':\n",
    "                num_pos += 1\n",
    "            else:\n",
    "                num_neg += 1\n",
    "            \n",
    "            for word in docu[0]:\n",
    "#                 if len(word) == 1 and word not in exceptions:\n",
    "#                     continue\n",
    "                \n",
    "                if word == ',' or word == '.':\n",
    "                    negation = False\n",
    "                    continue\n",
    "                if word == 'not' or word == 'no' or word == 't':\n",
    "                    negation = True\n",
    "                    continue\n",
    "                \n",
    "                if negation: # Negation 시 not_word\n",
    "                    word = 'not_'+ word \n",
    "                if word not in docu_word[pos_neg]:\n",
    "                    self.word_count(word, pos_neg)\n",
    "                    docu_word[pos_neg][word] = 1\n",
    "            \n",
    "        \n",
    "        return (num_pos, num_neg)\n",
    "                    \n",
    "    def log_likelihood(self):\n",
    "        # Log-likelihood 계산\n",
    "        count_all_pos = 0\n",
    "        count_all_neg = 0\n",
    "        for word in self.pos_words:\n",
    "            count_all_pos = count_all_pos + self.pos_words[word] + 1\n",
    "        \n",
    "        for word in self.neg_words:\n",
    "            count_all_neg = count_all_neg + self.neg_words[word] + 1\n",
    "            \n",
    "        for word in self.pos_words:\n",
    "            self.log_likelihood_pos[word] = math.log2((self.pos_words[word] + 1)  \n",
    "                                                / count_all_pos)\n",
    "        \n",
    "        for word in self.neg_words:\n",
    "            self.log_likelihood_neg[word] = math.log2((self.neg_words[word] + 1) \n",
    "                                                / count_all_neg)\n",
    "        self.smoothing_pos = math.log2(1 / count_all_pos)\n",
    "        self.smoothing_neg = math.log2(1 / count_all_neg)\n",
    "        \n",
    "        \n",
    "    def train(self, training_data):\n",
    "        # Triaing 과정\n",
    "        num_doc = len(training_data)\n",
    "        print('num doc : %d' %(num_doc))\n",
    "        # pos/neg 단어 빈도수 계산\n",
    "        num_pos, num_neg = self.calculate_frequency(training_data)\n",
    "        \n",
    "        \n",
    "        self.log_prior['pos'] = math.log2(num_pos / num_doc)\n",
    "        self.log_prior['neg'] = math.log2(num_neg / num_doc)\n",
    "        \n",
    "        self.log_likelihood()\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        sum_pos = self.log_prior['pos']\n",
    "        sum_neg = self.log_prior['neg']\n",
    "        word_in_docu_pos = {}\n",
    "        word_in_docu_neg = {}\n",
    "        negation = False\n",
    "        # Bag-of-words로 구현\n",
    "        for word in test_data[0]:\n",
    "            if word == 'not' or word == 'no' or word == 't':\n",
    "                negation = True\n",
    "                continue\n",
    "            \n",
    "            if negation:\n",
    "                word = 'not_'\n",
    "            if word in self.log_likelihood_pos:\n",
    "                if word in word_in_docu_pos:\n",
    "                    continue\n",
    "                else:\n",
    "                    sum_pos += self.log_likelihood_pos[word]\n",
    "                    word_in_docu_pos[word] = 1\n",
    "            else:\n",
    "                if not word in word_in_docu_pos:\n",
    "                    sum_pos += self.smoothing_pos\n",
    "                    word_in_docu_pos[word] = 1\n",
    "            if word in self.log_likelihood_neg:\n",
    "                if word in word_in_docu_neg:\n",
    "                    continue\n",
    "                else:\n",
    "                    sum_neg += self.log_likelihood_neg[word]\n",
    "                    word_in_docu_neg[word] = 1\n",
    "            else:\n",
    "                if not word in word_in_docu_neg:\n",
    "                    sum_neg += self.smoothing_neg\n",
    "                    word_in_docu_neg[word] = 1\n",
    "\n",
    "        if sum_pos > sum_neg:\n",
    "            return 'pos'\n",
    "        else:\n",
    "            return 'neg'\n",
    "\n",
    "        \n",
    "    \n",
    "    # Accuracy 계산\n",
    "    def accuracy(self, test_data):\n",
    "        data_size = len(test_data)\n",
    "        correct_num = 0\n",
    "        for docu in test_data:\n",
    "            if self.predict(docu) == docu[1]:\n",
    "                correct_num += 1\n",
    "                \n",
    "        return float(correct_num / data_size)\n",
    "                \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "        for category in movie_reviews.categories()\n",
    "        for fileid in movie_reviews.fileids(category)]\n",
    "# Random Shuffle with the random seed\n",
    "random.seed(19890914)\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "[0.845, 0.81, 0.83, 0.83, 0.785, 0.815, 0.86, 0.825, 0.775, 0.815]\n",
      "average :  0.819\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "iter_ = 0\n",
    "\n",
    "for training_test in fold_10(documents):\n",
    "    \n",
    "    training_data = training_test[0]\n",
    "    test_data = training_test[1]\n",
    "    \n",
    "    naive_bayes = NaiveBayesClassifier()\n",
    "    naive_bayes.train(training_data)\n",
    "    \n",
    "    accuracy = naive_bayes.accuracy(test_data)\n",
    "\n",
    "    accuracy_list.append(accuracy)\n",
    "    iter_ += 1\n",
    "    \n",
    "print(accuracy_list)\n",
    "print('average : ', (sum(accuracy_list) / len(accuracy_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "[0.985, 0.98, 0.965, 0.96, 0.97, 1.0, 0.995, 0.98, 0.98, 0.815]\n",
      "average :  0.9629999999999999\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "iter_ = 0\n",
    "\n",
    "for training_test in fold_10(documents):\n",
    "    \n",
    "    training_data = training_test[0]\n",
    "    test_data = training_test[1]\n",
    "    \n",
    "    naive_bayes_binary = NaiveBayesClassifierBinary()\n",
    "    naive_bayes_binary.train(training_data)\n",
    "    \n",
    "    accuracy = naive_bayes.accuracy(test_data)\n",
    "\n",
    "    accuracy_list.append(accuracy)\n",
    "    iter_ += 1\n",
    "    \n",
    "print(accuracy_list)\n",
    "print('average : ', (sum(accuracy_list) / len(accuracy_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "[0.71, 0.71, 0.73, 0.725, 0.66, 0.745, 0.705, 0.67, 0.615, 0.635]\n",
      "average :  0.6905\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "iter_ = 0\n",
    "\n",
    "for training_test in fold_10(documents):\n",
    "\n",
    "    training_data = training_test[0]\n",
    "    test_data = training_test[1]\n",
    "\n",
    "    naive_bayes_negation = NaiveBayesClassifierNegation()\n",
    "    naive_bayes_negation.train(training_data)\n",
    "\n",
    "    accuracy = naive_bayes_negation.accuracy(test_data)\n",
    "\n",
    "    accuracy_list.append(accuracy)\n",
    "    iter_ += 1\n",
    "\n",
    "print(accuracy_list)\n",
    "print('average : ', (sum(accuracy_list) / len(accuracy_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Negation Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "num doc : 1800\n",
      "[0.69, 0.665, 0.7, 0.69, 0.64, 0.725, 0.695, 0.635, 0.6, 0.635]\n",
      "average :  0.6674999999999999\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "iter_ = 0\n",
    "\n",
    "for training_test in fold_10(documents):\n",
    "\n",
    "    training_data = training_test[0]\n",
    "    test_data = training_test[1]\n",
    "\n",
    "    naive_bayes_negation_binary = NaiveBayesClassifierNegationBinary()\n",
    "    naive_bayes_negation_binary.train(training_data)\n",
    "\n",
    "    accuracy = naive_bayes_negation_binary.accuracy(test_data)\n",
    "\n",
    "    accuracy_list.append(accuracy)\n",
    "    iter_ += 1\n",
    "\n",
    "print(accuracy_list)\n",
    "print('average : ', (sum(accuracy_list) / len(accuracy_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
